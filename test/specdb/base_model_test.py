# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.

import unittest
from typing import Optional

from facto.inputgen.utils.config import TensorConfig
from facto.modelgen.gen import OpModelGenerator
from facto.specdb.db import SpecDictDB
from facto.utils.ops import get_op_overload


class BaseModelTest(unittest.TestCase):
    """Base test class for validating all models generated by OpModelGenerator."""

    def _run_model(
        self, op_name: str, *, config: Optional[TensorConfig] = None, max_count: int = 5
    ):
        """
        Run a single model in SpecDB with a given TensorConfig

        This test calls OpModelGenerator.gen with valid=True for a single operation.
        The operation is tested as a subtest.
        """
        print("Testing model: ", op_name)
        with self.subTest(op=op_name):
            try:
                # Get the spec and operation
                spec = SpecDictDB[op_name]
                op = get_op_overload(op_name)
                generator = OpModelGenerator(op, spec, config)
            except Exception as e:
                # If we can't resolve the operation or there's another issue,
                # fail this subtest with a descriptive message
                self.fail(
                    f"Failed to create model generator for operation {op_name}: {e}"
                )

            try:
                # Generate models and test them
                model_count = 0
                for model, args, kwargs in generator.gen(
                    valid=True, max_count=max_count
                ):
                    model_count += 1
                    success, output, error = generator.test_model_with_inputs(
                        model, args, kwargs
                    )
                    if not success:
                        self.fail(
                            f"Model failed for {op_name} (model {model_count}): {error}"
                        )

                if model_count == 0:
                    self.fail(f"No models generated for {op_name}")

            except Exception as e:
                self.fail(f"Failed while testing models for operation {op_name}: {e}")

    def _run_all_models(
        self, *, config: Optional[TensorConfig] = None, skip_ops=[], max_count: int = 5
    ):
        """
        Run all models in SpecDB with a given TensorConfig

        This test iterates through all operations in SpecDB and creates
        OpModelGenerator instances for each operation. Each operation is tested as a subtest.
        """
        # Get all operation names from SpecDB
        op_names = list(SpecDictDB.keys())

        for op_name in op_names:
            if op_name in skip_ops:
                continue
            self._run_model(op_name, config=config, max_count=max_count)
